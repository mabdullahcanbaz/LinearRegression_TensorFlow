{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9a5716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.10.1-cp39-cp39-macosx_10_9_x86_64.whl (14.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.2 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=5.3.0\n",
      "  Downloading Pillow-8.3.2-cp39-cp39-macosx_10_10_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 105.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from torchvision) (1.21.2)\n",
      "Collecting torch==1.9.1\n",
      "  Downloading torch-1.9.1-cp39-none-macosx_10_9_x86_64.whl (218.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 218.8 MB 114.5 MB/s eta 0:00:01  |███████▎                        | 49.4 MB 8.0 MB/s eta 0:00:22\n",
      "\u001b[?25hCollecting typing-extensions\n",
      "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: typing-extensions, torch, pillow, torchvision\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed pillow-8.3.2 torch-1.9.1 torchvision-0.10.1 typing-extensions-3.10.0.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.3 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fee6f2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fba1f2",
   "metadata": {},
   "source": [
    "Lets play with pytorch a little bit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8fbfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensors.\n",
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True)\n",
    "b = torch.tensor(5., requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44d5c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "994f9ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c09e3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5., requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed158f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(17., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = w*x+b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473415a2",
   "metadata": {},
   "source": [
    "What makes PyTorch special, is that we can automatically compute the derivative of y w.r.t. the tensors that have requires_grad set to True i.e. w and b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062b2307",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() #compute gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ec566db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dw: tensor(3.)\n",
      "dy/db: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print('dy/dw:',w.grad) #display gradients\n",
    "print('dy/db:',b.grad)#display gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a07a1c",
   "metadata": {},
   "source": [
    "# Now is a real problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13bc839",
   "metadata": {},
   "source": [
    "We'll create a model that predicts crop yeilds for apples and oranges (target variables) by looking at the average temperature, rainfall and humidity (input variables or features) in a region. \n",
    "\n",
    "In a linear regression model, each target variable is estimated to be a weighted sum of the input variables, offset by some constant, known as a bias :\n",
    "\n",
    "yeild_apple  = w11 * temp + w12 * rainfall + w13 * humidity + b1\n",
    "yeild_orange = w21 * temp + w22 * rainfall + w23 * humidity + b2\n",
    "\n",
    "\n",
    "Our objective: Find a suitable set of weights and biases using the training data, to make accurate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda85ec1",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d59d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], \n",
    "                   [91, 88, 64], \n",
    "                   [87, 134, 58], \n",
    "                   [102, 43, 37], \n",
    "                   [69, 96, 70]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b301d56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], \n",
    "                    [81, 101], \n",
    "                    [119, 133], \n",
    "                    [22, 37], \n",
    "                    [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0e291",
   "metadata": {},
   "source": [
    "Before we build a model, we need to convert inputs and targets to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27e35130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]])\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Convert inputs and targets to tensors\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)\n",
    "print(inputs)\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abe25bb",
   "metadata": {},
   "source": [
    "### Linear Regression Model (from scratch)\n",
    "\n",
    "The weights and biases can also be represented as matrices, initialized with random values. The first row of w and the first element of b are use to predict the first target variable i.e. yield for apples, and similarly the second for oranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14a48d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1623, -1.9893, -0.5136],\n",
      "        [ 0.2625,  0.9617, -1.7172]], requires_grad=True)\n",
      "tensor([1.5063, 0.5398], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75619a6f",
   "metadata": {},
   "source": [
    "The model is simply a function that performs a matrix multiplication of the input x and the weights w (transposed) and adds the bias b (replicated for each observation).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe6562e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f410ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-165.7104,   10.2922],\n",
      "        [-221.1931,   -0.8497],\n",
      "        [-308.9682,   52.6415],\n",
      "        [-119.5939,    5.1264],\n",
      "        [-236.6178,   -9.2336]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b5e7b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# Compare with targets\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33654a40",
   "metadata": {},
   "source": [
    "Because we've started with random weights and biases, the model does not a very good job of predicting the target varaibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597c6270",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "We can compare the predictions with the actual targets, using the following method:\n",
    "\n",
    "Calculate the difference between the two matrices (preds and targets).\n",
    "Square all elements of the difference matrix to remove negative values.\n",
    "Calculate the average of the elements in the resulting matrix.\n",
    "The result is a single number, known as the mean squared error (MSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e703a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE loss\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b845e7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49687.7734, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Compute loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190ee44e",
   "metadata": {},
   "source": [
    "The resulting number is called the loss, because it indicates how bad the model is at predicting the target variables. Lower the loss, better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595d156",
   "metadata": {},
   "source": [
    "### Compute Gradients\n",
    "\n",
    "With PyTorch, we can automatically compute the gradient or derivative of the loss w.r.t. to the weights and biases, because they have requires_grad set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81c0e42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ba67caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1623, -1.9893, -0.5136],\n",
      "        [ 0.2625,  0.9617, -1.7172]], requires_grad=True)\n",
      "tensor([[-23758.7754, -27497.4375, -16541.6562],\n",
      "        [ -6543.4824,  -7482.4448,  -4780.4570]])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for weights\n",
    "print(w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8bcc355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5063, 0.5398], requires_grad=True)\n",
      "tensor([-286.6167,  -80.4046])\n"
     ]
    }
   ],
   "source": [
    "# Gradients for bias\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a3e9d",
   "metadata": {},
   "source": [
    "A key insight from calculus is that the gradient indicates the rate of change of the loss, or the slope of the loss function w.r.t. the weights and biases.\n",
    "\n",
    "If a gradient element is postive,\n",
    "increasing the element's value slightly will increase the loss.\n",
    "decreasing the element's value slightly will decrease the loss.\n",
    "\n",
    "If a gradient element is negative,\n",
    "increasing the element's value slightly will decrease the loss.\n",
    "decreasing the element's value slightly will increase the loss.\n",
    "\n",
    "The increase or decrease is proportional to the value of the gradient.\n",
    "\n",
    "Finally, we'll reset the gradients to zero before moving forward, because PyTorch accumulates gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "788020e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673c43a",
   "metadata": {},
   "source": [
    "### Adjust weights and biases using gradient descent\n",
    "\n",
    "We'll reduce the loss and improve our model using the gradient descent algorithm, which has the following steps:\n",
    "\n",
    "1- Generate predictions\n",
    "\n",
    "2- Calculate the loss\n",
    "\n",
    "3- Compute gradients w.r.t the weights and biases\n",
    "\n",
    "4- Adjust the weights by subtracting a small quantity proportional to the gradient\n",
    "\n",
    "5- Reset the gradients to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cfd8bb8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-165.7104,   10.2922],\n",
      "        [-221.1931,   -0.8497],\n",
      "        [-308.9682,   52.6415],\n",
      "        [-119.5939,    5.1264],\n",
      "        [-236.6178,   -9.2336]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96c63ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(49687.7734, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate the loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "deb66d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute gradients\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10363b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust weights & reset gradients\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d90108ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0753, -1.7143, -0.3482],\n",
      "        [ 0.3279,  1.0365, -1.6694]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e476e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(34063.0469, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a51abf",
   "metadata": {},
   "source": [
    "### Train for multiple epochs\n",
    "\n",
    "To reduce the loss further, we repeat the process of adjusting the weights and biases using the gradients multiple times. Each iteration is called an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe2b3c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad * 1e-5\n",
    "        b -= b.grad * 1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a32b54c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(679.1196, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Calculate loss\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec4b9224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 66.3564,  74.4609],\n",
       "        [ 88.1411,  86.3452],\n",
       "        [ 90.4253, 158.8649],\n",
       "        [ 72.9992,  58.8916],\n",
       "        [ 82.2460,  81.5582]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print predictions\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b56dd1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60b1433",
   "metadata": {},
   "source": [
    "### Linear Regression Model using PyTorch built-ins\n",
    "\n",
    "Let's re-implement the same model using some built-in functions and classes from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b168014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7588ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input (temp, rainfall, humidity)\n",
    "inputs = np.array([[73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70], [73, 67, 43], [91, 88, 64], [87, 134, 58], [102, 43, 37], [69, 96, 70]], dtype='float32')\n",
    "# Targets (apples, oranges)\n",
    "targets = np.array([[56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119], \n",
    "                    [56, 70], [81, 101], [119, 133], [22, 37], [103, 119]], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cc7037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6609399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensor dataset & data loader\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ca3bef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 73.,  67.,  43.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 134.,  58.]]),\n",
       " tensor([[ 56.,  70.],\n",
       "         [ 81., 101.],\n",
       "         [119., 133.]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8241b30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 69.,  96.,  70.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [102.,  43.,  37.],\n",
       "         [ 87., 134.,  58.],\n",
       "         [ 91.,  88.,  64.]]),\n",
       " tensor([[103., 119.],\n",
       "         [ 81., 101.],\n",
       "         [ 22.,  37.],\n",
       "         [119., 133.],\n",
       "         [ 81., 101.]])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cc2e9",
   "metadata": {},
   "source": [
    "### nn.Linear\n",
    "Instead of initializing the weights & biases manually, we can define the model using nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e53b1989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2081, -0.3960, -0.4368],\n",
      "        [-0.3419,  0.0262,  0.5476]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2675,  0.3396], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = nn.Linear(3, 2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e422ca",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "Instead of manually manipulating the weights & biases using gradients, we can use the optimizer optim.SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12b74f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "opt = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e0f139",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "Instead of defining a loss function manually, we can use the built-in loss function mse_loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89c8f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import nn.functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37fa1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fbb03c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12401.4365, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs), targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d2e08",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We are ready to train the model now. We can define a utility function fit which trains the model for a given number of epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39595dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt):\n",
    "    for epoch in range(num_epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            # Generate predictions\n",
    "            pred = model(xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            # Perform gradient descent\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "    print('Training loss: ', loss_fn(model(inputs), targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93d15e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  tensor(28.0611, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Train the model for 100 epochs\n",
    "fit(100, model, loss_fn, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4c9902b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 59.0768,  70.9656],\n",
       "        [ 79.7396, 100.8391],\n",
       "        [120.9883, 131.4860],\n",
       "        [ 32.2651,  40.4978],\n",
       "        [ 91.0668, 117.4694],\n",
       "        [ 59.0768,  70.9656],\n",
       "        [ 79.7396, 100.8391],\n",
       "        [120.9883, 131.4860],\n",
       "        [ 32.2651,  40.4978],\n",
       "        [ 91.0668, 117.4694],\n",
       "        [ 59.0768,  70.9656],\n",
       "        [ 79.7396, 100.8391],\n",
       "        [120.9883, 131.4860],\n",
       "        [ 32.2651,  40.4978],\n",
       "        [ 91.0668, 117.4694]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2e2f0c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.],\n",
       "        [ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare with targets\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d03c7",
   "metadata": {},
   "source": [
    "# Bonus: Feedfoward Neural Network\n",
    "\n",
    "Conceptually, you think of feedforward neural networks as two or more linear regression models stacked on top of one another with a non-linear activation function applied between them.\n",
    "\n",
    "\n",
    "To use a feedforward neural network instead of linear regression, we can extend the nn.Module class from PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "79278fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    # Initialize the layers\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(3, 3)\n",
    "        self.act1 = nn.ReLU() # Activation function\n",
    "        self.linear2 = nn.Linear(3, 2)\n",
    "    \n",
    "    # Perform the computation\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27cce8e",
   "metadata": {},
   "source": [
    "Now we can define the model, optimizer and loss function exactly as before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "befa7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleNet()\n",
    "opt = torch.optim.SGD(model.parameters(), 1e-5)\n",
    "loss_fn = F.mse_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "32d84c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:  tensor(18.3240, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "fit(100, model, loss_fn, opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cfe507",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
